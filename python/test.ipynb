{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing c:\\home\\conda\\feedstock_root\\build_artifacts\\appnope_1649077682618\\work (from -r requirements.txt (line 3))\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'C:\\\\home\\\\conda\\\\feedstock_root\\\\build_artifacts\\\\appnope_1649077682618\\\\work'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='This is a test.', role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Say this is a test\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4-1106-preview\",\n",
    ")\n",
    "chat_completion.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.llm.utils import schema_to_openai_func\n",
    "\n",
    "\n",
    "def _new_file(full_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Create a new file at the given path. Returns \"success\" if successful, otherwise an error message.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def _remove_lines(start: int, end: int) -> str:\n",
    "    \"\"\"\n",
    "    Remove the lines between the given start and end line numbers. Returns \"success\" if successful, otherwise an error message.\n",
    "    \"\"\"\n",
    "    \n",
    "def _insert_lines(at: int, append_content: str) -> str:\n",
    "    \"\"\"\n",
    "    Insert the given content at the given line number. Returns \"success\" if successful, otherwise an error message.\n",
    "    \"\"\"\n",
    "    \n",
    "def _replace_lines(start: int, end: int, new_content: str) -> str:\n",
    "    \"\"\"\n",
    "    Replace the lines between the given start and end line numbers with the given content. Returns \"success\" if successful, otherwise an error message.\n",
    "    \"\"\"\n",
    "\n",
    "def _execute_command(command: str) -> str:\n",
    "    \"\"\"\n",
    "    Execute the given command in the integrated terminal. Returns the output of the command.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class FakeProject:\n",
    "    def __init__(self):\n",
    "        self.files = {} # {full_path: content}\n",
    "        self.current_file = None # set by open_file\n",
    "\n",
    "    def new_file(self, full_path: str):\n",
    "        if full_path in self.files:\n",
    "            return f\"File already exists at {full_path}\"\n",
    "        self.files[full_path] = \"\"\n",
    "        return \"success\"\n",
    "    \n",
    "    def open_file(self, full_path: str):\n",
    "        if full_path not in self.files:\n",
    "            return f\"File does not exist at {full_path}\"\n",
    "        self.current_file = full_path\n",
    "        return \"success\"\n",
    "    \n",
    "    def remove_lines(self, start: int, end: int):\n",
    "        if start > end:\n",
    "            return \"Start line cannot be greater than end line.\"\n",
    "        if not self.current_file:\n",
    "            return \"No file is currently open, please open a file first using the open_file tool.\"\n",
    "        \n",
    "        lines = self.files[self.current_file].split(\"\\n\")\n",
    "        if start > len(lines):\n",
    "            return \"Start line is greater than the number of lines in the file.\"\n",
    "        if end > len(lines):\n",
    "            return \"End line is greater than the number of lines in the file.\"\n",
    "        \n",
    "        self.files[self.current_file] = \"\\n\".join(lines[:start] + lines[end:])\n",
    "        return \"success\"\n",
    "\n",
    "class remove_lines(BaseModel):\n",
    "    \"\"\"\n",
    "    Remove the lines between the given start and end line numbers. Returns \"success\" if successful, otherwise an error message.\n",
    "    \"\"\"\n",
    "    start: int = Field(description=\"The line number to start removing at.\")\n",
    "    end: int = Field(description=\"The line number to stop removing at.\")\n",
    "\n",
    "class insert_lines(BaseModel):\n",
    "    \"\"\"\n",
    "    Insert the given content at the given line number. Returns \"success\" if successful, otherwise an error message.\n",
    "    \"\"\"\n",
    "    at: int = Field(description=\"The line number to insert at.\")\n",
    "    append_content: str = Field(description=\"The content to insert.\")\n",
    "\n",
    "class replace_lines(BaseModel):\n",
    "    \"\"\"\n",
    "    Replace the lines between the given start and end line numbers with the given content. Returns \"success\" if successful, otherwise an error message.\n",
    "    \"\"\"\n",
    "    start: int = Field(description=\"The line number to start replacing at.\")\n",
    "    end: int = Field(description=\"The line number to stop replacing at.\")\n",
    "    new_content: str = Field(description=\"The content to replace with.\")\n",
    "\n",
    "class new_file(BaseModel):\n",
    "    \"\"\"\n",
    "    Create a new file at the given path. Returns \"success\" if successful, otherwise an error message.\n",
    "    \"\"\"\n",
    "    full_path: str = Field(description=\"The full path of the file to create.\")\n",
    "    \n",
    "\n",
    "class execute_command(BaseModel):\n",
    "    \"\"\"\n",
    "    Execute the given command in the integrated terminal. Returns the output of the command.\n",
    "    \"\"\"\n",
    "    command: str = Field(description=\"The command to execute.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function(arguments='{\"full_path\": \"src/main.py\"}', name='new_file')\n",
      "Function(arguments='{\"at\": 1, \"append_content\": \"print(\\'hello world\\')\"}', name='insert_lines')\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "SYSTEM = \"\"\"\n",
    "You are an AI copilot directly integrated into an IDE. You have full access to the interface of the IDE by calling the provided function tools, such as creating new files, writing to files, and executing commands on the integrated terminal.\n",
    "When the user requests something, you should call a sequence of appropriate functions to fulfill the request.\n",
    "For example, when the user requests \"make and execute a simple hello world python program\", you should call the following functions:\n",
    "1. new_file(\"src/main.py\")\n",
    "2. insert_lines(1, \"print('hello world')\")\n",
    "3. execute_command(\"python src/main.py\")\n",
    "\"\"\"\n",
    "\n",
    "tools = [\n",
    "  schema_to_openai_func(new_file),\n",
    "  schema_to_openai_func(remove_lines),\n",
    "  schema_to_openai_func(execute_command),\n",
    "  schema_to_openai_func(insert_lines),\n",
    "  schema_to_openai_func(replace_lines)\n",
    "]\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": SYSTEM},\n",
    "    {\"role\": \"user\", \"content\": \"make and execute a simple hello world python program\"}\n",
    "  ]\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4-1106-preview\",\n",
    "  messages=messages,\n",
    "  tools=tools,\n",
    "  tool_choice=\"auto\",\n",
    "  temperature=0.0,\n",
    ")\n",
    "\n",
    "my_project = FakeProject()\n",
    "\n",
    "for tool_call in completion.choices[0].message.tool_calls:\n",
    "    f = tool_call.function\n",
    "    print(f)\n",
    "    if f.name == 'new_file':\n",
    "        full_path = f.arguments[\"full_path\"]\n",
    "        ret_val = my_project.new_file(full_path)\n",
    "\n",
    "        # insert the return value into the message\n",
    "        messages.append({\"role\": \"function\", \"content\": ret_val})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "\n",
    "```python\n",
    "from fastapi import APIRouter\n",
    "from app.services import hello_service\n",
    "\n",
    "router = APIRouter()\n",
    "\n",
    "\n",
    "@router.get(\"/test\")\n",
    "def hello_controller(query_string: str):\n",
    "    result = hello_service.hello(query_string)\n",
    "    return result\n",
    "\n",
    "@router.get(\"/user_action\")\n",
    "def user_action_controller(query_string: str):\n",
    "    result = hello_service.user_action(query_string)\n",
    "    return result\n",
    "\n",
    "<CURSOR>\n",
    "def ai_action_controller(query_string: str):\n",
    "    pass\n",
    "```\n",
    "\n",
    "Where <CURSOR> denotes the current postion of the cursor. Any code you write using insert_text function tool will insert that content in the place of the cursor.\n",
    "\n",
    "Turn the ai_action_controller into an endpoint.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
