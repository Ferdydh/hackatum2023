{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastapi~=0.101.1 (from -r requirements.txt (line 1))\n",
      "  Downloading fastapi-0.101.1-py3-none-any.whl (65 kB)\n",
      "                                              0.0/65.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 65.8/65.8 kB 3.5 MB/s eta 0:00:00\n",
      "Collecting uvicorn (from -r requirements.txt (line 2))\n",
      "  Downloading uvicorn-0.24.0.post1-py3-none-any.whl (59 kB)\n",
      "                                              0.0/59.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 59.7/59.7 kB 3.3 MB/s eta 0:00:00\n",
      "Collecting python-dotenv~=1.0.0 (from -r requirements.txt (line 3))\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Collecting starlette~=0.27.0 (from -r requirements.txt (line 4))\n",
      "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
      "                                              0.0/67.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 67.0/67.0 kB ? eta 0:00:00\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in c:\\users\\jw000\\anaconda3\\lib\\site-packages (from fastapi~=0.101.1->-r requirements.txt (line 1)) (2.5.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\jw000\\anaconda3\\lib\\site-packages (from fastapi~=0.101.1->-r requirements.txt (line 1)) (4.6.3)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\jw000\\anaconda3\\lib\\site-packages (from uvicorn->-r requirements.txt (line 2)) (8.0.4)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\jw000\\anaconda3\\lib\\site-packages (from uvicorn->-r requirements.txt (line 2)) (0.14.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\jw000\\anaconda3\\lib\\site-packages (from starlette~=0.27.0->-r requirements.txt (line 4)) (3.5.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\jw000\\anaconda3\\lib\\site-packages (from anyio<5,>=3.4.0->starlette~=0.27.0->-r requirements.txt (line 4)) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\jw000\\anaconda3\\lib\\site-packages (from anyio<5,>=3.4.0->starlette~=0.27.0->-r requirements.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jw000\\anaconda3\\lib\\site-packages (from click>=7.0->uvicorn->-r requirements.txt (line 2)) (0.4.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\jw000\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi~=0.101.1->-r requirements.txt (line 1)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.3 in c:\\users\\jw000\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi~=0.101.1->-r requirements.txt (line 1)) (2.14.3)\n",
      "Installing collected packages: python-dotenv, uvicorn, starlette, fastapi\n",
      "Successfully installed fastapi-0.101.1 python-dotenv-1.0.0 starlette-0.27.0 uvicorn-0.24.0.post1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='This is a test.', role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Say this is a test\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4-1106-preview\",\n",
    ")\n",
    "chat_completion.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.llm.utils import schema_to_openai_func\n",
    "\n",
    "\n",
    "def _new_file(full_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Create a new file at the given path. Returns \"success\" if successful, otherwise an error message.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def _write_file(full_path: str, content: str) -> str:\n",
    "    \"\"\"\n",
    "    Write the given content to the given file. Returns \"success\" if successful, otherwise an error message.\n",
    "    \"\"\"\n",
    "\n",
    "def _execute_command(command: str) -> str:\n",
    "    \"\"\"\n",
    "    Execute the given command in the integrated terminal. Returns the output of the command.\n",
    "    \"\"\"\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class new_file(BaseModel):\n",
    "    \"\"\"\n",
    "    Create a new file at the given path. Returns \"success\" if successful, otherwise an error message.\n",
    "    \"\"\"\n",
    "    full_path: str = Field(description=\"The full path of the file to create.\")\n",
    "    \n",
    "class write_file(BaseModel):\n",
    "    \"\"\"\n",
    "    Write the given content to the given file. Returns \"success\" if successful, otherwise an error message.\n",
    "    \"\"\"\n",
    "    full_path: str = Field(description=\"The full path of the file to write to.\")\n",
    "    content: str = Field(description=\"The content to write to the file.\")\n",
    "\n",
    "class execute_command(BaseModel):\n",
    "    \"\"\"\n",
    "    Execute the given command in the integrated terminal. Returns the output of the command.\n",
    "    \"\"\"\n",
    "    command: str = Field(description=\"The command to execute.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function(arguments='{\"full_path\":\"src/main.py\"}', name='new_file')\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "SYSTEM = \"\"\"\n",
    "You are an AI copilot directly integrated into an IDE. You have full access to the interface of the IDE by calling the provided function tools, such as creating new files, writing to files, and executing commands on the integrated terminal.\n",
    "When the user requests something, you should call a sequence of appropriate functions to fulfill the request.\n",
    "For example, when the user requests \"make and run a simple hello world python program\", you should call the following functions:\n",
    "1. new_file(\"src/main.py\")\n",
    "2. write_file(\"src/main.py\", \"print('hello world')\")\n",
    "3. execute_command(\"python src/main.py\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "tools = [\n",
    "  schema_to_openai_func(new_file),\n",
    "  schema_to_openai_func(write_file),\n",
    "  schema_to_openai_func(execute_command)\n",
    "]\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": SYSTEM},\n",
    "    {\"role\": \"user\", \"content\": \"make and run a simple hello world python program\"}\n",
    "  ]\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4-1106-preview\",\n",
    "  messages=messages,\n",
    "  tools=tools,\n",
    "  tool_choice=\"auto\",\n",
    "  temperature=0.0,\n",
    ")\n",
    "\n",
    "for tool_call in completion.choices[0].message.tool_calls:\n",
    "    print(tool_call.function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function(arguments='{\"full_path\":\"src/hello_world.py\"}', name='new_file')\n"
     ]
    }
   ],
   "source": [
    "for tool_call in completion.choices[0].message.tool_calls:\n",
    "    print(tool_call.function)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
